{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893a8b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, f1_score, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb58d6e",
   "metadata": {},
   "source": [
    "# Основные моменты\n",
    "\n",
    "1. Данные не нормализованы, поэтому надо прописать хороший пайплайн, который будет делать предобработку данных.\n",
    "\n",
    "2. Проверить работу базовых алгоритмов классификации, при этом для каждой модели провести тщательный подбор гиперпараметров, чтобы выявить те алгоритмы и подходы, которые в этой задаче будут давать наилушие значения:\n",
    "    * SGDCLassifier\n",
    "    * KNN\n",
    "    * SVC\n",
    "\n",
    "В данной файле рассмотрим только базовые модели, ансабли будут рассмотрены позже\n",
    "\n",
    "\n",
    "Также лучшие рузальтаты будут записаны в таблицу, а лучшие модели сохранены."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92abb29",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b69bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово! Все в float32\n",
      "X_train: (184506, 702), память: 494.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Загрузка\n",
    "train_df = pd.read_csv('./data/train_processed.csv')\n",
    "val_df = pd.read_csv('./data/val_processed.csv')\n",
    "\n",
    "X_train_raw = train_df.drop(columns=['TARGET'])\n",
    "y_train = train_df['TARGET'].astype(np.int8)\n",
    "X_val_raw = val_df.drop(columns=['TARGET'])\n",
    "y_val = val_df['TARGET'].astype(np.int8)\n",
    "\n",
    "# Определяем признаки для нормализации\n",
    "numeric_features = X_train_raw.select_dtypes(include=['int64', 'float64']).columns\n",
    "features_to_scale = [col for col in numeric_features if X_train_raw[col].nunique() > 2]\n",
    "\n",
    "# Нормализация\n",
    "if features_to_scale:\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Все нормализуемые признаки -> float32\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw[features_to_scale].astype(np.float32))\n",
    "    X_val_scaled = scaler.transform(X_val_raw[features_to_scale].astype(np.float32))\n",
    "    \n",
    "    # Создаем DataFrame\n",
    "    X_train = pd.DataFrame(X_train_scaled.astype(np.float32), columns=features_to_scale)\n",
    "    X_val = pd.DataFrame(X_val_scaled.astype(np.float32), columns=features_to_scale)\n",
    "    \n",
    "    # Добавляем остальные признаки (тоже в float32)\n",
    "    other_features = [col for col in X_train_raw.columns if col not in features_to_scale]\n",
    "    for col in other_features:\n",
    "        X_train[col] = X_train_raw[col].astype(np.float32)\n",
    "        X_val[col] = X_val_raw[col].astype(np.float32)\n",
    "else:\n",
    "    # Все признаки в float32\n",
    "    X_train = X_train_raw.astype(np.float32)\n",
    "    X_val = X_val_raw.astype(np.float32)\n",
    "\n",
    "# Очистка\n",
    "del X_train_raw, X_val_raw, train_df, val_df\n",
    "\n",
    "print(f\"Готово! Все в float32\")\n",
    "print(f\"X_train: {X_train.shape}, память: {X_train.memory_usage().sum()/1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce406f0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac0163b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Запуск RandomizedSearchCV для SGDClassifier...\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "\n",
      "Лучшие параметры:\n",
      "{'penalty': 'elasticnet', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.01, 'class_weight': 'balanced', 'alpha': np.float64(0.0008858667904100823)}\n",
      "\n",
      "Лучшее значение ROC-AUC на кросс-валидации: 0.7622\n",
      "\n",
      "==================================================\n",
      "ОЦЕНКА НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ\n",
      "==================================================\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81     56537\n",
      "           1       0.17      0.69      0.27      4965\n",
      "\n",
      "    accuracy                           0.70     61502\n",
      "   macro avg       0.57      0.69      0.54     61502\n",
      "weighted avg       0.90      0.70      0.77     61502\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39738 16799]\n",
      " [ 1556  3409]]\n",
      "Accuracy: 0.7016\n",
      "F1 Macro: 0.5416\n",
      "ROC-AUC: 0.7617\n",
      "\n",
      "Сохранение модели и scaler...\n",
      "Модель сохранена!\n"
     ]
    }
   ],
   "source": [
    "# 6. Создаем базовую модель SGDClassifier (логистическая регрессия через SGD)\n",
    "base_model = SGDClassifier(\n",
    "    loss='log_loss',  # Это делает её логистической регрессией\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1,\n",
    "    early_stopping=True,  # Ранняя остановка\n",
    "    validation_fraction=0.1,  # Часть данных для валидации\n",
    "    n_iter_no_change=5  # Остановка если нет улучшений 5 итераций\n",
    ")\n",
    "\n",
    "# 7. Определение сетки гиперпараметров для RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'alpha': np.logspace(-6, 1, 20),  # Параметр регуляризации (аналог 1/C)\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'l1_ratio': [0, 0.15, 0.5, 0.85, 1],  # Для elasticnet\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'eta0': [0.01, 0.1, 0.5],  # Начальная скорость обучения\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# 8. Настройка RandomizedSearchCV\n",
    "print(\"\\nЗапуск RandomizedSearchCV для SGDClassifier...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "print(random_search.best_params_)\n",
    "print(f\"\\nЛучшее значение ROC-AUC на кросс-валидации: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 9. Извлечение лучшей модели\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# 10. Оценка на валидационной выборке\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ОЦЕНКА НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"F1 Macro: {f1_score(y_val, y_val_pred, average='macro'):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_val, y_val_pred_proba):.4f}\")\n",
    "\n",
    "# 11. Сохранение модели и scaler\n",
    "print(\"\\nСохранение модели и scaler...\")\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'numeric_features': numeric_features,\n",
    "    'best_params': random_search.best_params_,\n",
    "    'cv_score': random_search.best_score_\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, './models/best_sgd_logistic_regression.pkl')\n",
    "print(\"Модель сохранена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1a712f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Добавлена модель: SGDClassifier\n",
      "        model  accuracy     f1  roc_auc\n",
      "SGDClassifier    0.7016 0.5416   0.7617\n"
     ]
    }
   ],
   "source": [
    "# 1. В начале ноутбука создаем пустой список\n",
    "model_results = []\n",
    "\n",
    "# 2. После КАЖДОЙ обученной модели:\n",
    "def log_model(model, X_val, y_val, name):\n",
    "    \"\"\"Записывает метрики модели в таблицу\"\"\"\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    result = {\n",
    "        'model': name,\n",
    "        'accuracy': round(accuracy_score(y_val, y_pred), 4),\n",
    "        'f1': round(f1_score(y_val, y_pred, average='macro'), 4)\n",
    "    }\n",
    "    \n",
    "    # ROC-AUC если доступен\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_val)\n",
    "            if len(model.classes_) == 2:\n",
    "                result['roc_auc'] = round(roc_auc_score(y_val, y_proba[:, 1]), 4)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    model_results.append(result)\n",
    "    \n",
    "    # Создаем DataFrame и показываем\n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    print(f\"\\nДобавлена модель: {name}\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "artifacts = joblib.load('./models/best_sgd_logistic_regression.pkl')\n",
    "\n",
    "results = log_model(artifacts['model'], X_val, y_val, 'SGDClassifier')\n",
    "results.to_csv('results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc676ada",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02355b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ОБУЧЕНИЕ SUPPORT VECTOR MACHINE (SVM)\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. Проверка данных\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРазмеры данных: X_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mX_train\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, X_val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТипы данных: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.dtypes.unique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mКлассы: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.unique(y_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ОБУЧЕНИЕ SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Проверка данных\n",
    "print(f\"Размеры данных: X_train: {X_train.shape}, X_val: {X_val.shape}\")\n",
    "print(f\"Типы данных: {X_train.dtypes.unique()}\")\n",
    "print(f\"Классы: {np.unique(y_train)}\")\n",
    "\n",
    "# 2. Проверяем баланс классов\n",
    "print(f\"\\nБаланс классов в train:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(f\"\\nБаланс классов в val:\")\n",
    "print(pd.Series(y_val).value_counts(normalize=True))\n",
    "\n",
    "# 3. Определяем, нужно ли использовать подвыборку для поиска\n",
    "# SVM очень медленная на больших данных\n",
    "use_subsample_for_search = len(X_train) > 30000\n",
    "\n",
    "if use_subsample_for_search:\n",
    "    print(f\"\\n{'!'*60}\")\n",
    "    print(f\"ВНИМАНИЕ: SVM может быть очень медленной на больших данных!\")\n",
    "    print(f\"Размер тренировочных данных: {len(X_train)} samples\")\n",
    "    print(f\"Использую подвыборку для поиска гиперпараметров...\")\n",
    "    print(f\"{'!'*60}\")\n",
    "    \n",
    "    # Берем подвыборку для быстрого поиска\n",
    "    search_sample_size = min(15000, len(X_train))\n",
    "    search_indices = np.random.choice(len(X_train), search_sample_size, replace=False)\n",
    "    X_train_search = X_train.iloc[search_indices]\n",
    "    y_train_search = y_train.iloc[search_indices]\n",
    "    \n",
    "    print(f\"Подвыборка для поиска параметров: {X_train_search.shape}\")\n",
    "    print(f\"(Случайная выборка из {len(X_train)} -> {search_sample_size} samples)\")\n",
    "else:\n",
    "    X_train_search = X_train\n",
    "    y_train_search = y_train\n",
    "    print(f\"\\nИспользую все данные для поиска параметров...\")\n",
    "\n",
    "# 4. Создаем базовую модель SVM\n",
    "# Начинаем с линейного ядра - он быстрее\n",
    "base_svm = SVC(\n",
    "    kernel='rbf',           # Начнем с RBF (можно поменять на 'linear' для скорости)\n",
    "    probability=True,       # Чтобы были predict_proba для ROC-AUC\n",
    "    random_state=42,\n",
    "    cache_size=500,         # Увеличиваем кэш для ускорения\n",
    "    verbose=False,          # Не выводить подробности обучения\n",
    "    class_weight='balanced' # Учитываем дисбаланс классов\n",
    ")\n",
    "\n",
    "# 5. Определение сетки гиперпараметров для RandomizedSearchCV\n",
    "# SVM имеет 2 основных гиперпараметра: C и gamma\n",
    "param_distributions = {\n",
    "    'C': np.logspace(-3, 3, 20),          # Параметр регуляризации\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 1, 10)),  # Для RBF ядра\n",
    "    'kernel': ['rbf', 'linear', 'poly'],  # Типы ядер\n",
    "    'degree': [2, 3, 4],                  # Для полиномиального ядра\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0],        # Для poly и sigmoid ядер\n",
    "    'shrinking': [True, False],           # Использовать ли shrinking heuristic\n",
    "    'tol': [1e-4, 1e-3, 1e-2],            # Допуск для остановки\n",
    "    'max_iter': [-1, 1000, 2000]          # -1 = без ограничений\n",
    "}\n",
    "\n",
    "# 6. Настройка RandomizedSearchCV с подробным выводом\n",
    "n_iter = 15  # Уменьшаем количество итераций для скорости\n",
    "\n",
    "print(f\"\\nЗапуск RandomizedSearchCV для SVM...\")\n",
    "print(f\"Количество итераций: {n_iter}\")\n",
    "print(f\"Размер данных для поиска: {X_train_search.shape}\")\n",
    "print(f\"Количество фолдов: 3\")\n",
    "print(f\"Всего будет обучено: {n_iter * 3} моделей\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_svm,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=n_iter,\n",
    "    cv=3,                     # 3 фолда\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=1,                 # SVM плохо параллелится, лучше 1\n",
    "    verbose=10,               # БОЛЬШОЙ VERBOSE для детального вывода\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    error_score='raise',\n",
    "    return_train_score=True   # Чтобы видеть score на train\n",
    ")\n",
    "\n",
    "# 7. Подбор гиперпараметров\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"НАЧАЛО ПОДБОРА ГИПЕРПАРАМЕТРОВ SVM\")\n",
    "print(\"=\"*60)\n",
    "print(\"Будет выводиться прогресс по каждой комбинации параметров...\")\n",
    "print(\"Fitting 3 folds for each of 15 candidates, totalling 45 fits\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "random_search.fit(X_train_search, y_train_search)\n",
    "\n",
    "search_time = time.time() - start_time\n",
    "print(f\"\\nПоиск гиперпараметров завершен за {search_time/60:.1f} минут\")\n",
    "\n",
    "# 8. Вывод результатов поиска\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПОИСКА ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if use_subsample_for_search:\n",
    "    print(f\"Поиск выполнен на подвыборке: {X_train_search.shape}\")\n",
    "else:\n",
    "    print(f\"Поиск выполнен на всех данных: {X_train_search.shape}\")\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nЛучший ROC-AUC на кросс-валидации: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 9. Показываем топ-5 комбинаций параметров\n",
    "print(\"\\nТоп-5 лучших комбинаций параметров:\")\n",
    "results_df = pd.DataFrame(random_search.cv_results_)\n",
    "top_results = results_df.sort_values('mean_test_score', ascending=False).head(5)\n",
    "\n",
    "for i, (_, row) in enumerate(top_results.iterrows(), 1):\n",
    "    print(f\"\\n{i}. Score: {row['mean_test_score']:.4f} (+/- {row['std_test_score']:.4f})\")\n",
    "    params = row['params']\n",
    "    for key in ['C', 'kernel', 'gamma', 'degree']:\n",
    "        if key in params:\n",
    "            print(f\"   {key}: {params[key]}\")\n",
    "\n",
    "# 10. Если использовали подвыборку, обучаем финальную модель на всех данных\n",
    "if use_subsample_for_search:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ОБУЧЕНИЕ ФИНАЛЬНОЙ SVM НА ВСЕХ ДАННЫХ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    best_svm_params = random_search.best_params_\n",
    "    \n",
    "    # Убираем параметры, которые могут вызвать проблемы\n",
    "    if 'max_iter' in best_svm_params and best_svm_params['max_iter'] == -1:\n",
    "        best_svm_params['max_iter'] = 2000  # Ограничиваем итерации\n",
    "    \n",
    "    print(f\"Обучаем модель с лучшими параметрами на всех {len(X_train)} samples...\")\n",
    "    print(f\"Параметры: {best_svm_params}\")\n",
    "    print(\"Это может занять значительное время (возможно, несколько часов)...\")\n",
    "    print(\"Прогресс будет выводиться во время обучения...\")\n",
    "    \n",
    "    # Создаем финальную модель\n",
    "    final_svm = SVC(**best_svm_params, \n",
    "                   probability=True,\n",
    "                   random_state=42,\n",
    "                   cache_size=1000,  # Увеличиваем кэш для больших данных\n",
    "                   verbose=True)     # Включаем verbose для отслеживания прогресса\n",
    "    \n",
    "    # Засекаем время\n",
    "    train_start = time.time()\n",
    "    final_svm.fit(X_train, y_train)\n",
    "    train_time = time.time() - train_start\n",
    "        \n",
    "    best_model = final_svm\n",
    "    print(f\"\\nФинальная SVM модель обучена на всех данных за {train_time/60:.1f} минут!\")\n",
    "else:\n",
    "    best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c09527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ОЦЕНКА KNN НА 10,000 СЛУЧАЙНЫХ SAMPLES ИЗ ВАЛИДАЦИИ\n",
      "======================================================================\n",
      "\n",
      "1. Выборка 10000 случайных samples из 61502 валидационных...\n",
      "   Размер подвыборки: (10000, 702)\n",
      "\n",
      "2. Predict на 10000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 20/20 [04:27<00:00, 13.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Predict_proba на 10000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict probabilities: 100%|██████████| 20/20 [04:26<00:00, 13.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Расчет метрик на 10000 samples...\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ НА 10000 SAMPLES ИЗ ВАЛИДАЦИИ\n",
      "============================================================\n",
      "Accuracy: 0.9161\n",
      "F1 Macro: 0.4781\n",
      "ROC-AUC: 0.6518\n",
      "\n",
      "Время выполнения:\n",
      "  Predict: 267.3 секунд (4.5 минут)\n",
      "  Predict_proba: 266.7 секунд (4.4 минут)\n",
      "  Всего: 534.1 секунд (8.9 минут)\n",
      "\n",
      "Оценка времени для полной валидации (61502 samples):\n",
      "  Predict: ~27.4 минут\n",
      "  Predict_proba: ~27.3 минут\n",
      "  Всего: ~54.7 минут\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      9161\n",
      "           1       0.00      0.00      0.00       839\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.46      0.50      0.48     10000\n",
      "weighted avg       0.84      0.92      0.88     10000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9161    0]\n",
      " [ 839    0]]\n",
      "\n",
      "==================================================\n",
      "СОХРАНЕНИЕ МОДЕЛИ KNN\n",
      "==================================================\n",
      "Модель KNN сохранена как './models/best_knn_model_10k_eval.pkl'\n",
      "\n",
      "======================================================================\n",
      "ОЦЕНКА ЗАВЕРШЕНА НА 10000 SAMPLES!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ОЦЕНКА KNN НА 10,000 СЛУЧАЙНЫХ SAMPLES ИЗ ВАЛИДАЦИИ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Выбираем 10,000 случайных samples из валидации\n",
    "sample_size = 10000\n",
    "print(f\"\\n1. Выборка {sample_size} случайных samples из {len(X_val)} валидационных...\")\n",
    "\n",
    "# Создаем случайные индексы без замены\n",
    "sample_indices = np.random.choice(len(X_val), sample_size, replace=False)\n",
    "X_val_sample = X_val.iloc[sample_indices]\n",
    "y_val_sample = y_val.iloc[sample_indices]\n",
    "\n",
    "print(f\"   Размер подвыборки: {X_val_sample.shape}\")\n",
    "\n",
    "# 2. Функция для предсказания с прогресс-баром по батчам\n",
    "def predict_batched_with_progress(model, X, batch_size=500, desc=\"Predicting\"):\n",
    "    \"\"\"Предсказание с прогресс-баром по батчам\"\"\"\n",
    "    predictions = []\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    for i in tqdm(range(0, n_samples, batch_size), desc=desc):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        X_batch = X.iloc[i:end_idx]\n",
    "        pred_batch = model.predict(X_batch)\n",
    "        predictions.extend(pred_batch)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "def predict_proba_batched_with_progress(model, X, batch_size=500, desc=\"Predicting probabilities\"):\n",
    "    \"\"\"Predict_proba с прогресс-баром по батчам\"\"\"\n",
    "    probabilities = []\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    for i in tqdm(range(0, n_samples, batch_size), desc=desc):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        X_batch = X.iloc[i:end_idx]\n",
    "        proba_batch = model.predict_proba(X_batch)[:, 1]\n",
    "        probabilities.extend(proba_batch)\n",
    "    \n",
    "    return np.array(probabilities)\n",
    "\n",
    "# 3. Predict на подвыборке\n",
    "print(f\"\\n2. Predict на {sample_size} samples...\")\n",
    "start_time = time.time()\n",
    "y_val_pred_sample = predict_batched_with_progress(\n",
    "    best_model, X_val_sample, batch_size=500, desc=\"Predict\"\n",
    ")\n",
    "predict_time = time.time() - start_time\n",
    "\n",
    "# 4. Predict_proba на подвыборке\n",
    "print(f\"\\n3. Predict_proba на {sample_size} samples...\")\n",
    "start_time_proba = time.time()\n",
    "y_val_pred_proba_sample = predict_proba_batched_with_progress(\n",
    "    best_model, X_val_sample, batch_size=500, desc=\"Predict probabilities\"\n",
    ")\n",
    "proba_time = time.time() - start_time_proba\n",
    "\n",
    "# 5. Расчет всех метрик\n",
    "print(f\"\\n4. Расчет метрик на {sample_size} samples...\")\n",
    "accuracy = accuracy_score(y_val_sample, y_val_pred_sample)\n",
    "f1 = f1_score(y_val_sample, y_val_pred_sample, average='macro')\n",
    "roc_auc = roc_auc_score(y_val_sample, y_val_pred_proba_sample)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"РЕЗУЛЬТАТЫ НА {sample_size} SAMPLES ИЗ ВАЛИДАЦИИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Macro: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nВремя выполнения:\")\n",
    "print(f\"  Predict: {predict_time:.1f} секунд ({predict_time/60:.1f} минут)\")\n",
    "print(f\"  Predict_proba: {proba_time:.1f} секунд ({proba_time/60:.1f} минут)\")\n",
    "print(f\"  Всего: {predict_time + proba_time:.1f} секунд ({(predict_time + proba_time)/60:.1f} минут)\")\n",
    "\n",
    "print(f\"\\nОценка времени для полной валидации ({len(X_val)} samples):\")\n",
    "print(f\"  Predict: ~{predict_time * len(X_val)/sample_size/60:.1f} минут\")\n",
    "print(f\"  Predict_proba: ~{proba_time * len(X_val)/sample_size/60:.1f} минут\")\n",
    "print(f\"  Всего: ~{(predict_time + proba_time) * len(X_val)/sample_size/60:.1f} минут\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_sample, y_val_pred_sample))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val_sample, y_val_pred_sample))\n",
    "\n",
    "# 6. Сохранение с полной структурой\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СОХРАНЕНИЕ МОДЕЛИ KNN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'numeric_features': numeric_features,\n",
    "    'best_params': random_search.best_params_,\n",
    "    'cv_score': random_search.best_score_,\n",
    "    'val_metrics': {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'sample_size': sample_size,\n",
    "        'total_val_size': len(X_val)\n",
    "    },\n",
    "    'timing': {\n",
    "        'predict_time_seconds': predict_time,\n",
    "        'proba_time_seconds': proba_time,\n",
    "        'total_time_seconds': predict_time + proba_time,\n",
    "        'estimated_full_predict_time_minutes': predict_time * len(X_val)/sample_size/60,\n",
    "        'estimated_full_proba_time_minutes': proba_time * len(X_val)/sample_size/60\n",
    "    },\n",
    "    'training_info': {\n",
    "        'model_type': 'KNeighborsClassifier',\n",
    "        'used_subsample_for_search': use_subsample,\n",
    "        'search_sample_size': X_train_search.shape[0] if use_subsample else X_train.shape[0],\n",
    "        'final_training_size': X_train.shape[0],\n",
    "        'feature_count': X_train.shape[1],\n",
    "        'validation_sample_size': sample_size,\n",
    "        'full_validation_size': len(X_val),\n",
    "        'sample_indices': sample_indices,  # сохраняем индексы для воспроизводимости\n",
    "        'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, './models/best_knn_model_10k_eval.pkl')\n",
    "print(\"Модель KNN сохранена как './models/best_knn_model_10k_eval.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"ОЦЕНКА ЗАВЕРШЕНА НА {sample_size} SAMPLES!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51925440",
   "metadata": {},
   "source": [
    "По полученным метрикам видим, что значения precision и recall для положительного класса равны 0, что говорит и том, что модель все данные называет 0, и так как этих классов боьшинство, то и значения метрик выгляидит неплохим, а на деле модель всё подряд предсказвыает 0.\n",
    "\n",
    "Данные из этой модели записывать в матрицу резульаттов даже не будем, чтобы значениями метрик не вводило в заблуждение.\n",
    "\n",
    "Вычисление гиперпарамтеров и метрик по всей выборке затруднительно, так как алгоритм медленный, а данных для него сильно много, из-за чего приходится использвать подвыборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e3f12",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd596548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ОБУЧЕНИЕ SUPPORT VECTOR MACHINE (SVM)\n",
      "======================================================================\n",
      "Размеры данных: X_train: (184506, 702), X_val: (61502, 702)\n",
      "Типы данных: [dtype('float32')]\n",
      "Классы: [0 1]\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "ВНИМАНИЕ: SVM может быть очень медленной на больших данных!\n",
      "Размер тренировочных данных: 184506 samples\n",
      "Использую подвыборку для поиска гиперпараметров...\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Подвыборка для поиска параметров: (10000, 702)\n",
      "(Случайная выборка из 184506 -> 10000 samples)\n",
      "\n",
      "Запуск RandomizedSearchCV для SVM...\n",
      "Количество итераций: 15\n",
      "Размер данных для поиска: (10000, 702)\n",
      "Количество фолдов: 3\n",
      "Всего будет обучено: 45 моделей\n",
      "\n",
      "============================================================\n",
      "НАЧАЛО ПОДБОРА ГИПЕРПАРАМЕТРОВ SVM\n",
      "============================================================\n",
      "Будет выводиться прогресс по каждой комбинации параметров...\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "------------------------------------------------------------\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV 1/3; 1/15] START C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 1/3; 1/15] END C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.988, test=0.671) total time=  30.3s\n",
      "[CV 2/3; 1/15] START C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 2/3; 1/15] END C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.989, test=0.705) total time=  32.4s\n",
      "[CV 3/3; 1/15] START C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 3/3; 1/15] END C=2.976351441631316, coef0=1.0, degree=2, gamma=auto, kernel=poly, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.990, test=0.675) total time=  47.9s\n",
      "[CV 1/3; 2/15] START C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01\n",
      "[CV 1/3; 2/15] END C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01;, score=(train=0.990, test=0.605) total time=  23.1s\n",
      "[CV 2/3; 2/15] START C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01\n",
      "[CV 2/3; 2/15] END C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01;, score=(train=0.991, test=0.638) total time=  22.0s\n",
      "[CV 3/3; 2/15] START C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01\n",
      "[CV 3/3; 2/15] END C=26.366508987303554, coef0=0.0, degree=3, gamma=10.0, kernel=poly, max_iter=2000, shrinking=False, tol=0.01;, score=(train=0.991, test=0.619) total time=  22.5s\n",
      "[CV 1/3; 3/15] START C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001\n",
      "[CV 1/3; 3/15] END C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001;, score=(train=0.555, test=0.503) total time=  11.1s\n",
      "[CV 2/3; 3/15] START C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001\n",
      "[CV 2/3; 3/15] END C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001;, score=(train=0.525, test=0.509) total time=  11.0s\n",
      "[CV 3/3; 3/15] START C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001\n",
      "[CV 3/3; 3/15] END C=6.158482110660261, coef0=0.5, degree=4, gamma=0.46415888336127775, kernel=linear, max_iter=1000, shrinking=False, tol=0.001;, score=(train=0.616, test=0.562) total time=  10.9s\n",
      "[CV 1/3; 4/15] START C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 1/3; 4/15] END C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.993, test=0.701) total time=  41.4s\n",
      "[CV 2/3; 4/15] START C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 2/3; 4/15] END C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.993, test=0.726) total time=  42.3s\n",
      "[CV 3/3; 4/15] START C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01\n",
      "[CV 3/3; 4/15] END C=1.438449888287663, coef0=0.0, degree=2, gamma=scale, kernel=rbf, max_iter=5000, shrinking=True, tol=0.01;, score=(train=0.993, test=0.705) total time=  40.6s\n",
      "[CV 1/3; 5/15] START C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 1/3; 5/15] END C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01;, score=(train=1.000, test=0.612) total time=  23.5s\n",
      "[CV 2/3; 5/15] START C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 2/3; 5/15] END C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01;, score=(train=1.000, test=0.645) total time=  23.5s\n",
      "[CV 3/3; 5/15] START C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 3/3; 5/15] END C=2.976351441631316, coef0=0.5, degree=2, gamma=0.46415888336127775, kernel=poly, max_iter=10000, shrinking=False, tol=0.01;, score=(train=1.000, test=0.613) total time=  23.8s\n",
      "[CV 1/3; 6/15] START C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 1/3; 6/15] END C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.606, test=0.535) total time=  24.7s\n",
      "[CV 2/3; 6/15] START C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 2/3; 6/15] END C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.584, test=0.566) total time=  24.6s\n",
      "[CV 3/3; 6/15] START C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 3/3; 6/15] END C=1.438449888287663, coef0=0.5, degree=3, gamma=0.1668100537200059, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.593, test=0.527) total time=  24.3s\n",
      "[CV 1/3; 7/15] START C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001\n",
      "[CV 1/3; 7/15] END C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001;, score=(train=1.000, test=0.572) total time= 1.4min\n",
      "[CV 2/3; 7/15] START C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001\n",
      "[CV 2/3; 7/15] END C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001;, score=(train=1.000, test=0.587) total time= 1.4min\n",
      "[CV 3/3; 7/15] START C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001\n",
      "[CV 3/3; 7/15] END C=0.0379269019073225, coef0=0.1, degree=2, gamma=0.05994842503189409, kernel=rbf, max_iter=10000, shrinking=False, tol=0.001;, score=(train=1.000, test=0.566) total time= 1.4min\n",
      "[CV 1/3; 8/15] START C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001\n",
      "[CV 1/3; 8/15] END C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001;, score=(train=0.612, test=0.563) total time=  17.3s\n",
      "[CV 2/3; 8/15] START C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001\n",
      "[CV 2/3; 8/15] END C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001;, score=(train=0.571, test=0.544) total time=  17.1s\n",
      "[CV 3/3; 8/15] START C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001\n",
      "[CV 3/3; 8/15] END C=12.742749857031322, coef0=0.0, degree=4, gamma=10.0, kernel=linear, max_iter=2000, shrinking=False, tol=0.0001;, score=(train=0.539, test=0.462) total time=  16.8s\n",
      "[CV 1/3; 9/15] START C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01\n",
      "[CV 1/3; 9/15] END C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01;, score=(train=1.000, test=0.503) total time=  21.0s\n",
      "[CV 2/3; 9/15] START C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01\n",
      "[CV 2/3; 9/15] END C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01;, score=(train=1.000, test=0.500) total time=  20.2s\n",
      "[CV 3/3; 9/15] START C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01\n",
      "[CV 3/3; 9/15] END C=112.88378916846884, coef0=0.0, degree=4, gamma=1.2915496650148828, kernel=rbf, max_iter=1000, shrinking=True, tol=0.01;, score=(train=1.000, test=0.503) total time=  20.5s\n",
      "[CV 1/3; 10/15] START C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001\n",
      "[CV 1/3; 10/15] END C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001;, score=(train=0.978, test=0.708) total time= 1.1min\n",
      "[CV 2/3; 10/15] START C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001\n",
      "[CV 2/3; 10/15] END C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001;, score=(train=0.975, test=0.733) total time= 1.1min\n",
      "[CV 3/3; 10/15] START C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001\n",
      "[CV 3/3; 10/15] END C=0.3359818286283781, coef0=0.1, degree=4, gamma=0.0027825594022071257, kernel=rbf, max_iter=10000, shrinking=True, tol=0.0001;, score=(train=0.976, test=0.703) total time= 1.1min\n",
      "[CV 1/3; 11/15] START C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 1/3; 11/15] END C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01;, score=(train=0.581, test=0.531) total time=  33.9s\n",
      "[CV 2/3; 11/15] START C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 2/3; 11/15] END C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01;, score=(train=0.535, test=0.499) total time=  33.9s\n",
      "[CV 3/3; 11/15] START C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01\n",
      "[CV 3/3; 11/15] END C=1.438449888287663, coef0=1.0, degree=3, gamma=0.021544346900318832, kernel=linear, max_iter=10000, shrinking=False, tol=0.01;, score=(train=0.659, test=0.580) total time=  33.6s\n",
      "[CV 1/3; 12/15] START C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 1/3; 12/15] END C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.606, test=0.535) total time=  25.8s\n",
      "[CV 2/3; 12/15] START C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 2/3; 12/15] END C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.584, test=0.566) total time=  25.9s\n",
      "[CV 3/3; 12/15] START C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001\n",
      "[CV 3/3; 12/15] END C=6.158482110660261, coef0=0.0, degree=4, gamma=0.001, kernel=linear, max_iter=5000, shrinking=True, tol=0.0001;, score=(train=0.593, test=0.527) total time=  26.0s\n",
      "[CV 1/3; 13/15] START C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001\n",
      "[CV 1/3; 13/15] END C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001;, score=(train=0.555, test=0.503) total time=  11.7s\n",
      "[CV 2/3; 13/15] START C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001\n",
      "[CV 2/3; 13/15] END C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001;, score=(train=0.525, test=0.509) total time=  11.7s\n",
      "[CV 3/3; 13/15] START C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001\n",
      "[CV 3/3; 13/15] END C=112.88378916846884, coef0=1.0, degree=3, gamma=1.2915496650148828, kernel=linear, max_iter=1000, shrinking=False, tol=0.0001;, score=(train=0.616, test=0.562) total time=  11.7s\n",
      "[CV 1/3; 14/15] START C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001\n",
      "[CV 1/3; 14/15] END C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001;, score=(train=0.612, test=0.563) total time=  17.1s\n",
      "[CV 2/3; 14/15] START C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001\n",
      "[CV 2/3; 14/15] END C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001;, score=(train=0.571, test=0.544) total time=  17.2s\n",
      "[CV 3/3; 14/15] START C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001\n",
      "[CV 3/3; 14/15] END C=483.2930238571752, coef0=0.1, degree=4, gamma=0.021544346900318832, kernel=linear, max_iter=2000, shrinking=True, tol=0.001;, score=(train=0.539, test=0.462) total time=  16.8s\n",
      "[CV 1/3; 15/15] START C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001\n",
      "[CV 1/3; 15/15] END C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001;, score=(train=0.855, test=0.727) total time=  43.9s\n",
      "[CV 2/3; 15/15] START C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001\n",
      "[CV 2/3; 15/15] END C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001;, score=(train=0.851, test=0.737) total time=  43.5s\n",
      "[CV 3/3; 15/15] START C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001\n",
      "[CV 3/3; 15/15] END C=0.00206913808111479, coef0=0.5, degree=2, gamma=0.05994842503189409, kernel=linear, max_iter=5000, shrinking=False, tol=0.0001;, score=(train=0.853, test=0.728) total time=  43.4s\n",
      "\n",
      "Поиск гиперпараметров завершен за 28.9 минут\n",
      "\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ ПОИСКА ГИПЕРПАРАМЕТРОВ\n",
      "============================================================\n",
      "Поиск выполнен на подвыборке: (10000, 702)\n",
      "\n",
      "Лучшие параметры:\n",
      "  tol: 0.0001\n",
      "  shrinking: False\n",
      "  max_iter: 5000\n",
      "  kernel: linear\n",
      "  gamma: 0.05994842503189409\n",
      "  degree: 2\n",
      "  coef0: 0.5\n",
      "  C: 0.00206913808111479\n",
      "\n",
      "Лучший ROC-AUC на кросс-валидации: 0.7307\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ОБУЧЕНИЕ SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Проверка данных\n",
    "print(f\"Размеры данных: X_train: {X_train.shape}, X_val: {X_val.shape}\")\n",
    "print(f\"Типы данных: {X_train.dtypes.unique()}\")\n",
    "print(f\"Классы: {np.unique(y_train)}\")\n",
    "\n",
    "\n",
    "# 3. Определяем, нужно ли использовать подвыборку для поиска\n",
    "# SVM очень медленная на больших данных\n",
    "use_subsample_for_search = len(X_train) > 30000\n",
    "\n",
    "if use_subsample_for_search:\n",
    "    print(f\"\\n{'!'*60}\")\n",
    "    print(f\"ВНИМАНИЕ: SVM может быть очень медленной на больших данных!\")\n",
    "    print(f\"Размер тренировочных данных: {len(X_train)} samples\")\n",
    "    print(f\"Использую подвыборку для поиска гиперпараметров...\")\n",
    "    print(f\"{'!'*60}\")\n",
    "    \n",
    "    # Берем подвыборку для быстрого поиска\n",
    "    search_sample_size = min(10000, len(X_train))\n",
    "    search_indices = np.random.choice(len(X_train), search_sample_size, replace=False)\n",
    "    X_train_search = X_train.iloc[search_indices]\n",
    "    y_train_search = y_train.iloc[search_indices]\n",
    "    \n",
    "    print(f\"Подвыборка для поиска параметров: {X_train_search.shape}\")\n",
    "    print(f\"(Случайная выборка из {len(X_train)} -> {search_sample_size} samples)\")\n",
    "else:\n",
    "    X_train_search = X_train\n",
    "    y_train_search = y_train\n",
    "    print(f\"\\nИспользую все данные для поиска параметров...\")\n",
    "\n",
    "# 4. Создаем базовую модель SVM\n",
    "# Начинаем с линейного ядра - он быстрее\n",
    "base_svm = SVC(\n",
    "    kernel='rbf',           # Начнем с RBF (можно поменять на 'linear' для скорости)\n",
    "    probability=True,       # Чтобы были predict_proba для ROC-AUC\n",
    "    random_state=42,\n",
    "    cache_size=500,         # Увеличиваем кэш для ускорения\n",
    "    verbose=False,          # Не выводить подробности обучения\n",
    "    class_weight='balanced', # Учитываем дисбаланс классов\n",
    ")\n",
    "\n",
    "# 5. Определение сетки гиперпараметров для RandomizedSearchCV\n",
    "# SVM имеет 2 основных гиперпараметра: C и gamma\n",
    "param_distributions = {\n",
    "    'C': np.logspace(-3, 3, 20),          # Параметр регуляризации\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 1, 10)),  # Для RBF ядра\n",
    "    'kernel': ['rbf', 'linear', 'poly'],  # Типы ядер\n",
    "    'degree': [2, 3, 4],                  # Для полиномиального ядра\n",
    "    'coef0': [0.0, 0.1, 0.5, 1.0],        # Для poly и sigmoid ядер\n",
    "    'shrinking': [True, False],           # Использовать ли shrinking heuristic\n",
    "    'tol': [1e-4, 1e-3, 1e-2],            # Допуск для остановки\n",
    "    'max_iter': [1000, 2000, 5000, 10000]          # -1 = без ограничений\n",
    "}\n",
    "\n",
    "# 6. Настройка RandomizedSearchCV с подробным выводом\n",
    "n_iter = 15  # Уменьшаем количество итераций для скорости\n",
    "\n",
    "print(f\"\\nЗапуск RandomizedSearchCV для SVM...\")\n",
    "print(f\"Количество итераций: {n_iter}\")\n",
    "print(f\"Размер данных для поиска: {X_train_search.shape}\")\n",
    "print(f\"Количество фолдов: 3\")\n",
    "print(f\"Всего будет обучено: {n_iter * 3} моделей\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_svm,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=n_iter,\n",
    "    cv=3,                     # 3 фолда\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=1,                 # SVM плохо параллелится, лучше 1\n",
    "    verbose=10,               # БОЛЬШОЙ VERBOSE для детального вывода\n",
    "    random_state=42,\n",
    "    refit=True,\n",
    "    error_score='raise',\n",
    "    return_train_score=True   # Чтобы видеть score на train\n",
    ")\n",
    "\n",
    "# 7. Подбор гиперпараметров\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"НАЧАЛО ПОДБОРА ГИПЕРПАРАМЕТРОВ SVM\")\n",
    "print(\"=\"*60)\n",
    "print(\"Будет выводиться прогресс по каждой комбинации параметров...\")\n",
    "print(\"Fitting 3 folds for each of 15 candidates, totalling 45 fits\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "random_search.fit(X_train_search, y_train_search)\n",
    "\n",
    "search_time = time.time() - start_time\n",
    "print(f\"\\nПоиск гиперпараметров завершен за {search_time/60:.1f} минут\")\n",
    "\n",
    "# 8. Вывод результатов поиска\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПОИСКА ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if use_subsample_for_search:\n",
    "    print(f\"Поиск выполнен на подвыборке: {X_train_search.shape}\")\n",
    "else:\n",
    "    print(f\"Поиск выполнен на всех данных: {X_train_search.shape}\")\n",
    "\n",
    "print(\"\\nЛучшие параметры:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nЛучший ROC-AUC на кросс-валидации: {random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb514a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ОБУЧЕНИЕ SVM НА 50,000 СЛУЧАЙНЫХ SAMPLES\n",
      "==================================================\n",
      "Использую 50000 случайных samples из 184506 тренировочных данных\n",
      "Размер подвыборки: (50000, 702)\n",
      "Параметры модели: {'tol': 0.0001, 'shrinking': False, 'max_iter': 5000, 'kernel': 'linear', 'gamma': np.float64(0.05994842503189409), 'degree': 2, 'coef0': 0.5, 'C': np.float64(0.00206913808111479)}\n",
      "Обучение начнется сейчас...\n",
      "\n",
      "Начало обучения в 20:55:25...\n",
      "[LibSVM]\n",
      "Финальная SVM модель обучена на 50000 samples за 14.3 минут!\n",
      "Обучение завершено в 21:09:43\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ОБУЧЕНИЕ SVM НА 50,000 СЛУЧАЙНЫХ SAMPLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_svm_params = random_search.best_params_\n",
    "\n",
    "# Убираем параметры, которые могут вызвать проблемы\n",
    "if 'max_iter' in best_svm_params and best_svm_params['max_iter'] == -1:\n",
    "    best_svm_params['max_iter'] = 2000  # Ограничиваем итерации\n",
    "\n",
    "# Берем 50,000 случайных samples из тренировочных данных\n",
    "sample_size = 50000\n",
    "sample_indices = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "X_train_sample = X_train.iloc[sample_indices]\n",
    "y_train_sample = y_train.iloc[sample_indices]\n",
    "\n",
    "print(f\"Использую {sample_size} случайных samples из {len(X_train)} тренировочных данных\")\n",
    "print(f\"Размер подвыборки: {X_train_sample.shape}\")\n",
    "print(f\"Параметры модели: {best_svm_params}\")\n",
    "print(\"Обучение начнется сейчас...\")\n",
    "\n",
    "# Создаем финальную модель\n",
    "final_svm = SVC(**best_svm_params, \n",
    "                probability=True,\n",
    "                random_state=42,\n",
    "                cache_size=1000,  # Увеличиваем кэш для больших данных\n",
    "                verbose=True)     # Включаем verbose для отслеживания прогресса\n",
    "\n",
    "# Засекаем время\n",
    "train_start = time.time()\n",
    "print(f\"\\nНачало обучения в {time.strftime('%H:%M:%S')}...\")\n",
    "final_svm.fit(X_train_sample, y_train_sample)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "best_model = final_svm\n",
    "print(f\"\\nФинальная SVM модель обучена на {sample_size} samples за {train_time/60:.1f} минут!\")\n",
    "print(f\"Обучение завершено в {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Сохраняем информацию о том, на каких данных обучались\n",
    "training_sample_info = {\n",
    "    'sample_size': sample_size,\n",
    "    'sample_indices': sample_indices,\n",
    "    'training_time_minutes': train_time / 60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34b3679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ОЦЕНКА SVM НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ\n",
      "============================================================\n",
      "Предсказание для 61502 samples батчами по 2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 31/31 [04:43<00:00,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Расчет метрик...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56537\n",
      "           1       0.00      0.00      0.00      4965\n",
      "\n",
      "    accuracy                           0.92     61502\n",
      "   macro avg       0.46      0.50      0.48     61502\n",
      "weighted avg       0.85      0.92      0.88     61502\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56535     2]\n",
      " [ 4965     0]]\n",
      "\n",
      "Метрики:\n",
      "Accuracy: 0.9192\n",
      "F1 Macro: 0.4790\n",
      "ROC-AUC: 0.6261\n",
      "\n",
      "==================================================\n",
      "СОХРАНЕНИЕ МОДЕЛИ SVM\n",
      "==================================================\n",
      "Модель SVM сохранена как './models/best_svm_model.pkl'\n",
      "\n",
      "==================================================\n",
      "ДОПОЛНИТЕЛЬНАЯ ИНФОРМАЦИЯ\n",
      "==================================================\n",
      "Размер тренировочных данных: 184506 samples, 702 features\n",
      "Ядро SVM: linear\n",
      "Параметр C: 0.00206913808111479\n",
      "Параметр gamma: 0.05994842503189409\n",
      "Использовалась подвыборка для поиска: Да\n",
      "Размер подвыборки для поиска: 10000 samples\n",
      "Размер финального обучения: 184506 samples\n",
      "\n",
      "======================================================================\n",
      "Готово! SVM модель обучена и сохранена.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Оценка на валидационной выборке\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОЦЕНКА SVM НА ВАЛИДАЦИОННОЙ ВЫБОРКЕ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# SVM может быть медленной при предсказании, используем батчи\n",
    "def predict_svm_batched(model, X, batch_size=1000):\n",
    "    \"\"\"Предсказание SVM по батчам\"\"\"\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    print(f\"Предсказание для {n_samples} samples батчами по {batch_size}...\")\n",
    "    \n",
    "    for i in tqdm(range(0, n_samples, batch_size), desc=\"Predicting\"):\n",
    "        end_idx = min(i + batch_size, n_samples)\n",
    "        X_batch = X.iloc[i:end_idx]\n",
    "        \n",
    "        # Предсказания\n",
    "        pred_batch = model.predict(X_batch)\n",
    "        predictions.extend(pred_batch)\n",
    "        \n",
    "        # Вероятности\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            proba_batch = model.predict_proba(X_batch)[:, 1]\n",
    "            probabilities.extend(proba_batch)\n",
    "    \n",
    "    return np.array(predictions), np.array(probabilities) if probabilities else None\n",
    "\n",
    "# Быстрое предсказание\n",
    "y_val_pred, y_val_pred_proba = predict_svm_batched(best_model, X_val, batch_size=2000)\n",
    "\n",
    "print(\"\\nРасчет метрик...\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "print(f\"\\nМетрики:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"F1 Macro: {f1_score(y_val, y_val_pred, average='macro'):.4f}\")\n",
    "if y_val_pred_proba is not None:\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_val, y_val_pred_proba):.4f}\")\n",
    "\n",
    "# 11. Сохранение модели\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СОХРАНЕНИЕ МОДЕЛИ SVM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'numeric_features': numeric_features,\n",
    "    'best_params': random_search.best_params_,\n",
    "    'cv_score': random_search.best_score_,\n",
    "    'val_metrics': {\n",
    "        'accuracy': accuracy_score(y_val, y_val_pred),\n",
    "        'f1_macro': f1_score(y_val, y_val_pred, average='macro'),\n",
    "        'roc_auc': roc_auc_score(y_val, y_val_pred_proba) if y_val_pred_proba is not None else None\n",
    "    },\n",
    "    'training_info': {\n",
    "        'model_type': 'SVC',\n",
    "        'used_subsample_for_search': use_subsample_for_search,\n",
    "        'search_sample_size': X_train_search.shape[0] if use_subsample_for_search else X_train.shape[0],\n",
    "        'final_training_size': X_train.shape[0],\n",
    "        'feature_count': X_train.shape[1],\n",
    "        'validation_size': X_val.shape[0],\n",
    "        'kernel': best_model.kernel,\n",
    "        'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, './models/best_svm_model.pkl')\n",
    "print(\"Модель SVM сохранена как './models/best_svm_model.pkl'\")\n",
    "\n",
    "# 12. Дополнительная информация\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ДОПОЛНИТЕЛЬНАЯ ИНФОРМАЦИЯ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Размер тренировочных данных: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Ядро SVM: {best_model.kernel}\")\n",
    "print(f\"Параметр C: {best_model.C}\")\n",
    "if hasattr(best_model, 'gamma'):\n",
    "    print(f\"Параметр gamma: {best_model.gamma}\")\n",
    "print(f\"Использовалась подвыборка для поиска: {'Да' if use_subsample_for_search else 'Нет'}\")\n",
    "\n",
    "if use_subsample_for_search:\n",
    "    print(f\"Размер подвыборки для поиска: {X_train_search.shape[0]} samples\")\n",
    "    print(f\"Размер финального обучения: {X_train.shape[0]} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Готово! SVM модель обучена и сохранена.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f44715",
   "metadata": {},
   "source": [
    "Опять таки ситуация схожа с KNN, так как все пирмеры были определены как 0 класс, и лишь 2 примера как положительный. Увеличение выборки, на которой искать гиперпарметры, а также увеличение выборки, на которой обучать итогувю модель врятли сильно улучшит ситуацию. Данные модели для нашей задачи мало применимы из-за большого дисбаланса классов. \n",
    "\n",
    "Данные по этой модели также не будут вноситься в итогувую таблицу с моделями, так как там будет происхожить сравнение в выбор модели с лучшими результатми."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
